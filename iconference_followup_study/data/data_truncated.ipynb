{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Code Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "        sys.path.append(path)    \n",
    "add_path('/home/jjian03/anaconda3/lib/python3.7/site-packages')\n",
    "add_path(f'{os.path.abspath(os.path.join(\".\"))}/lib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated 16 CPUs\n"
     ]
    }
   ],
   "source": [
    "from lib.Repository import *\n",
    "from lib.Utility import *\n",
    "from lib.modeling import *\n",
    "from lib.preprocessing import *\n",
    "from lib.preprocessing.HTMLParser import html_parser\n",
    "from lib.viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size - raw_data: 14673\n",
      "Initialized\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14673 entries, 0 to 14672\n",
      "Data columns (total 36 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   id                                      14673 non-null  object \n",
      " 1   url                                     14673 non-null  object \n",
      " 2   actual_scrape_url                       14673 non-null  object \n",
      " 3   first_appear                            14673 non-null  int64  \n",
      " 4   first_available_timestamp               0 non-null      float64\n",
      " 5   last_available_timestamp                14673 non-null  int64  \n",
      " 6   header                                  14673 non-null  object \n",
      " 7   html_text                               14673 non-null  object \n",
      " 8   comment                                 14673 non-null  object \n",
      " 9   from_waybackmachine                     14673 non-null  int64  \n",
      " 10  http_status_code                        14673 non-null  int64  \n",
      " 11  original_check_failure                  14673 non-null  object \n",
      " 12  original_check_error_log                14673 non-null  object \n",
      " 13  terminate_reason                        14673 non-null  object \n",
      " 14  terminate_reason_error_log              14673 non-null  object \n",
      " 15  paperId                                 14673 non-null  int64  \n",
      " 16  total_num_of_paper_citing               14250 non-null  float64\n",
      " 17  total_num_of_author_citing              14250 non-null  float64\n",
      " 18  total_num_of_affiliation_citing         14128 non-null  float64\n",
      " 19  total_num_of_journal_citing             14195 non-null  float64\n",
      " 20  total_num_of_author_self_citation       10638 non-null  float64\n",
      " 21  total_num_of_affiliation_self_citation  8935 non-null   float64\n",
      " 22  total_num_of_journal_self_citation      6528 non-null   float64\n",
      " 23  avg_year                                14250 non-null  float64\n",
      " 24  min_year                                14250 non-null  float64\n",
      " 25  max_year                                14250 non-null  float64\n",
      " 26  median                                  7129 non-null   float64\n",
      " 27  num_of_author                           11766 non-null  float64\n",
      " 28  num_of_author_citing                    14250 non-null  float64\n",
      " 29  num_of_affiliation_citing               14128 non-null  float64\n",
      " 30  num_of_journal_citing                   14195 non-null  float64\n",
      " 31  avg_hindex                              14402 non-null  float64\n",
      " 32  first_author_hindex                     12575 non-null  float64\n",
      " 33  last_author_hindex                      14673 non-null  int64  \n",
      " 34  avg_mid_author_hindex                   11994 non-null  float64\n",
      " 35  paper_unique_affiliation                11766 non-null  float64\n",
      "dtypes: float64(20), int64(6), object(10)\n",
      "memory usage: 4.1+ MB\n",
      "raw_data: (14673, 36)\n",
      "--- 00 minutes, 6.10 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "start_time = time.time()\n",
    "raw_data = DataSource(job_name='generate_truncated_data', cache_name='trunc_data.csv', truncated=True, fract=.04).raw_data\n",
    "\n",
    "raw_data.info()\n",
    "\n",
    "print(f'raw_data: {shape(raw_data)}')\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6th Edition - Combine suffix dummy with MAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine import categorical_encoders\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('label_builder', TobitLabelBuilder()),\n",
    "    ('url_parser', URLParser()),\n",
    "    ('url_length_counter', URLLengthCounter()),\n",
    "    ('url_depth_counter', URLDepthCounter()),\n",
    "    ('has_www_converter', HasWWWConverter()),\n",
    "    ('subdomain_level_counter', SubdomainLevelCounter()),\n",
    "    ('request_parameter_counter', RequestParameterCounter()),\n",
    "    ('domain_suffix_builder', DomainSuffixBuilder()),\n",
    "    ('incorrect_domain_url_cleaner', IncorrectDomainUrlCleaner()),\n",
    "    ('column_renamer', ColumnRenamer({'scheme': 'protocol_type'})),\n",
    "    ('binary_na_encoder', BinaryNAEncoder(['content_type'])),\n",
    "    ('html_parser', html_parser),\n",
    "    ('binary_feature_converter', FeatureValueMapper('protocol_type', {\n",
    "                                        'http': 1,\n",
    "                                        'https':0,\n",
    "                                        })),\n",
    "\n",
    "    ('nan_to_Zero_converter', NanToZeroConverter([\n",
    "        'total_num_of_paper_citing',\n",
    "        'total_num_of_author_citing',\n",
    "        'total_num_of_affiliation_citing',\n",
    "        'total_num_of_journal_citing',\n",
    "        'total_num_of_author_self_citation',\n",
    "        'total_num_of_affiliation_self_citation',\n",
    "        'total_num_of_journal_self_citation',\n",
    "        'avg_year',\n",
    "        'min_year',\n",
    "        'max_year',\n",
    "        'median',\n",
    "        'num_of_author',\n",
    "        'num_of_author_citing',\n",
    "        'num_of_affiliation_citing',\n",
    "        'num_of_journal_citing',\n",
    "        'avg_hindex',\n",
    "        'first_author_hindex',\n",
    "        'last_author_hindex',\n",
    "        'avg_mid_author_hindex',\n",
    "        'paper_unique_affiliation'\n",
    "    ])),\n",
    "    \n",
    "    ('feature_picker', FeaturePicker([\n",
    "                                        'protocol_type',\n",
    "                                        'url_depth',\n",
    "                                        'has_www',\n",
    "                                        'subdomain_level',\n",
    "                                        'param_cnt',\n",
    "                                        'suffix_idx',\n",
    "                                        'is_port_access',\n",
    "                                        'code_size',\n",
    "                                        'title_length',\n",
    "                                        'internal_js_cnt',\n",
    "                                        'external_js_cnt',\n",
    "                                        'charset',\n",
    "                                        'is_html5',\n",
    "                                        'has_iframe',\n",
    "                                        'hyperlink_cnt',\n",
    "                                        'first_appear',\n",
    "\n",
    "                                        'total_num_of_paper_citing',\n",
    "                                        'total_num_of_author_citing',\n",
    "                                        'total_num_of_affiliation_citing',\n",
    "                                        'total_num_of_journal_citing',\n",
    "                                        'total_num_of_author_self_citation',\n",
    "                                        'total_num_of_affiliation_self_citation',\n",
    "                                        'total_num_of_journal_self_citation',\n",
    "                                        'avg_year',\n",
    "                                        'min_year',\n",
    "                                        'max_year',\n",
    "                                        'median',\n",
    "                                        'num_of_author',\n",
    "                                        'num_of_author_citing',\n",
    "                                        'num_of_affiliation_citing',\n",
    "                                        'num_of_journal_citing',\n",
    "                                        'avg_hindex',\n",
    "                                        'first_author_hindex',\n",
    "                                        'last_author_hindex',\n",
    "                                        'avg_mid_author_hindex',\n",
    "                                        'paper_unique_affiliation',\n",
    "\n",
    "                                        'label',\n",
    "                                       ])),\n",
    "    ('dummy_suffix_descritizer', DummySuffixDescritizer()),\n",
    "\n",
    "    ('feature_remover', FeatureRemover([\n",
    "                                        'is_port_access',\n",
    "                                       ])),\n",
    "    ('frequency_indexer', categorical_encoders.CountFrequencyCategoricalEncoder(\n",
    "        encoding_method='frequency',\n",
    "        variables=['charset'])),\n",
    "    ('standard_scaler', TobitCustomizedStandardizer(norm='l2')),\n",
    "\n",
    "])\n",
    "\n",
    "pipe.fit_transform(DataSource().raw_data).to_csv('trunc_data_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map_to_pandas(rdds):\n",
    "    \"\"\" Needs to be here due to pickling issues \"\"\"\n",
    "    return [pd.DataFrame(list(rdds))]\n",
    "\n",
    "def toPandas(df, n_partitions=None):\n",
    "    \"\"\"\n",
    "    Returns the contents of `df` as a local `pandas.DataFrame` in a speedy fashion. The DataFrame is\n",
    "    repartitioned if `n_partitions` is passed.\n",
    "    :param df:              pyspark.sql.DataFrame\n",
    "    :param n_partitions:    int or None\n",
    "    :return:                pandas.DataFrame\n",
    "    \"\"\"\n",
    "    if n_partitions is not None: df = df.repartition(n_partitions)\n",
    "    df_pand = df.rdd.mapPartitions(_map_to_pandas).collect()\n",
    "    df_pand = pd.concat(df_pand)\n",
    "    df_pand.columns = df.columns\n",
    "    return df_pand\n",
    "\n",
    "def load_dataset(spark, path, name):\n",
    "    return spark.read.parquet(path).registerTempTable(name)\n",
    "\n",
    "\n",
    "spark = SparkSession.builder. \\\n",
    "                config('spark.app.name', 'test_batch_pandas_export'). \\\n",
    "                config('spark.dynamicAllocation.enabled', 'true'). \\\n",
    "                config('spark.dynamicAllocation.maxExecutors', '50'). \\\n",
    "                config('spark.dynamicAllocation.executorIdleTimeout', '30s'). \\\n",
    "                config('spark.driver.maxResultSize', '8g'). \\\n",
    "                config('spark.driver.memory', '50g'). \\\n",
    "                config('spark.executor.memory', '10g'). \\\n",
    "                config('spark.task.maxFailures', '3'). \\\n",
    "                config('spark.yarn.am.memory', '50g'). \\\n",
    "                config('spark.yarn.max.executor.failures', '3'). \\\n",
    "                config('spark.kryoserializer.buffer.max', '1024m'). \\\n",
    "                config('spark.yarn.executor.memoryOverhead', '50g'). \\\n",
    "                getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark_sql = SQLContext(sc)\n",
    "\n",
    "load_dataset(spark, '/user/jjian03/WebResourceQuality.parquet', 'web_resource_quality')\n",
    "load_dataset(spark, '/user/jjian03/WebResourceQuality_pmid.parquet', 'web_resource_quality_pmid')\n",
    "load_dataset(spark, '/datasets/MAG_20200403/MAG_Azure_Parquet/mag_parquet/Papers.parquet', 'Paper')\n",
    "load_dataset(spark, '/user/lliang06/icon/MAG_publication_features.parquet', 'mag')\n",
    "\n",
    "seed=77\n",
    "fract=0.00003\n",
    "\n",
    "raw_data = spark_sql.sql(f'''\n",
    "        SELECT wr.id\n",
    "            , wr.url\n",
    "            , wr.actual_scrape_url\n",
    "            , wr.first_appear\n",
    "            , wr.first_available_timestamp\n",
    "            , wr.last_available_timestamp\n",
    "            , wr.header\n",
    "            , wr.html_text\n",
    "            , wr.comment\n",
    "            , wr.from_waybackmachine\n",
    "            , wr.http_status_code\n",
    "            , wr.original_check_failure\n",
    "            , wr.original_check_error_log\n",
    "            , wr.terminate_reason\n",
    "            , wr.terminate_reason_error_log\n",
    "\n",
    "            , m.paperId\n",
    "            , m.total_num_of_paper_citing\n",
    "            , m.total_num_of_author_citing\n",
    "            , m.total_num_of_affiliation_citing\n",
    "            , m.total_num_of_journal_citing\n",
    "            , m.total_num_of_author_self_citation\n",
    "            , m.total_num_of_affiliation_self_citation\n",
    "            , m.total_num_of_journal_self_citation\n",
    "            , m.avg_year\n",
    "            , m.min_year\n",
    "            , m.max_year\n",
    "            , m.median\n",
    "            , m.num_of_author\n",
    "            , m.num_of_author_citing\n",
    "            , m.num_of_affiliation_citing\n",
    "            , m.num_of_journal_citing\n",
    "            , m.avg_hindex\n",
    "            , m.first_author_hindex\n",
    "            , m.last_author_hindex\n",
    "            , m.avg_mid_author_hindex\n",
    "            , m.paper_unique_affiliation\n",
    "\n",
    "        FROM web_resource_quality wr\n",
    "        JOIN web_resource_quality_pmid wr_doi ON wr.id = wr_doi.id\n",
    "        JOIN Paper p ON wr_doi.doi = p.doi\n",
    "        JOIN mag m ON p.paperId = m.paperId\n",
    "        WHERE wr.label IS NOT NULL\n",
    "        AND wr.label IN (\"0\", \"1\")\n",
    "        AND isNaN(wr.label) = false\n",
    "        AND wr.first_appear IS NOT NULL\n",
    "        AND isNaN(wr.first_appear) = false\n",
    "        AND lower(wr.url) NOT LIKE \"%doi.org%\"\n",
    "    ''') \\\n",
    "    .orderBy(fn.rand(seed=seed)) \\\n",
    "    .sample(False, fract, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toPandas(raw_data, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "# spark = SparkSession.builder. \\\n",
    "#                 config('spark.app.name', 'elastic_net_reg'). \\\n",
    "#                 config('spark.dynamicAllocation.enabled', 'true'). \\\n",
    "#                 config('spark.dynamicAllocation.maxExecutors', '50'). \\\n",
    "#                 config('spark.dynamicAllocation.executorIdleTimeout', '30s'). \\\n",
    "#                 config('spark.driver.maxResultSize', '8g'). \\\n",
    "#                 config('spark.driver.memory', '50g'). \\\n",
    "#                 config('spark.executor.memory', '10g'). \\\n",
    "#                 config('spark.task.maxFailures', '3'). \\\n",
    "#                 config('spark.yarn.am.memory', '50g'). \\\n",
    "#                 config('spark.yarn.max.executor.failures', '3'). \\\n",
    "#                 config('spark.kryoserializer.buffer.max', '1024m'). \\\n",
    "#                 config('spark.yarn.executor.memoryOverhead', '50g'). \\\n",
    "#                 getOrCreate()\n",
    "print(spark)\n",
    "\n",
    "pdf = pd.DataFrame([1, 2, 3], columns=[\"x\"])\n",
    "df = spark.createDataFrame(pdf)\n",
    "\n",
    "# Declare the function and create the UDF\n",
    "@pandas_udf(\"long\")\n",
    "def plus_one(iterator: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    for x in iterator:\n",
    "        yield x + 1\n",
    "\n",
    "df.select(plus_one(\"x\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
