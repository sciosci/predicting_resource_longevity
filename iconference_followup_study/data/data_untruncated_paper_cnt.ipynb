{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Code Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "        sys.path.append(path)\n",
    "add_path('/home/jjian03/anaconda3/lib/python3.7/site-packages')\n",
    "add_path(f'{os.path.abspath(os.path.join(\"..\"))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "        sys.path.append(path)\n",
    "add_path('/home/jjian03/anaconda3/lib/python3.7/site-packages')\n",
    "add_path(f'{os.path.abspath(os.path.join(\"..\"))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0.cloudera2\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init('/opt/cloudera/parcels/SPARK2/lib/spark2/')\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as fn\n",
    "\n",
    "\n",
    "spark = SparkSession.builder. \\\n",
    "                config('spark.app.name', 'Jian Jian - Calculate the number of paper'). \\\n",
    "                config('spark.driver.memory', '20g').\\\n",
    "                config('spark.network.timeout', '600s').\\\n",
    "                config('spark.driver.maxResultSize', '10g').\\\n",
    "                config('spark.executor.memory', '15g').\\\n",
    "                config('spark.kryoserializer.buffer.max', '1g').\\\n",
    "                config('spark.cores.max', '50').\\\n",
    "                getOrCreate()\n",
    "\n",
    "\n",
    "def load_dataset(spark, path, name):\n",
    "    return spark.read.parquet(path).registerTempTable(name)\n",
    "\n",
    "load_dataset(spark, '/user/jjian03/WebResourceQuality.parquet', 'web_resource_quality')\n",
    "load_dataset(spark, '/user/jjian03/WebResourceQuality_pmid.parquet', 'web_resource_quality_pmid')\n",
    "load_dataset(spark, '/datasets/MAG_20200403/MAG_Azure_Parquet/mag_parquet/Papers.parquet', 'Paper')\n",
    "load_dataset(spark, '/user/lliang06/icon/MAG_publication_features.parquet', 'mag')\n",
    "\n",
    "sc = spark.sparkContext\n",
    "spark_sql = SQLContext(sc)\n",
    "print(spark.version)\n",
    "\n",
    "seed=77\n",
    "fract=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1965512, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete = spark_sql.sql(f'''\n",
    "    SELECT m.total_num_of_paper_citing, wr.url\n",
    "    FROM web_resource_quality wr\n",
    "    JOIN web_resource_quality_pmid wr_doi ON wr.id = wr_doi.id\n",
    "    JOIN Paper p ON wr_doi.doi = p.doi\n",
    "    JOIN mag m ON p.paperId = m.paperId\n",
    "    WHERE wr.label IS NOT NULL\n",
    "    AND wr.label IN (\"0\", \"1\")\n",
    "    AND isNaN(wr.label) = false\n",
    "    AND wr.first_appear IS NOT NULL\n",
    "    AND isNaN(wr.first_appear) = false\n",
    "    AND lower(wr.url) NOT LIKE \"%doi.org%\"\n",
    "''').toPandas()\n",
    "\n",
    "df_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58910, 2)\n",
      "(58910, 2)\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "df_sample = pd.read_csv(\"untrunc_data_cleaned_url.csv\")\n",
    "df_sample = df_sample.loc[:, [\"url\"]]\n",
    "df_sample.loc[:, 'idx'] = df_sample.url.apply(lambda x: uuid.uuid4())\n",
    "print(df_sample.shape)\n",
    "print(df_sample.drop_duplicates('idx').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58910, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_sample.merge(df_complete, on='url').drop_duplicates('idx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58910\n",
      "2548458.0\n"
     ]
    }
   ],
   "source": [
    "print(df.shape[0])\n",
    "print(df.total_num_of_paper_citing.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
