{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Code Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T23:24:36.138565Z",
     "start_time": "2021-01-24T23:24:36.131503Z"
    },
    "code_folding": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "        sys.path.append(path)\n",
    "add_path('/home/jjian03/anaconda3/lib/python3.7/site-packages')\n",
    "add_path('/home/jjian03/iconference_followup_study')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T23:24:38.544527Z",
     "start_time": "2021-01-24T23:24:36.144563Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58871 entries, 0 to 58909\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   protocol_type                           58871 non-null  float64\n",
      " 1   has_www                                 58871 non-null  float64\n",
      " 2   has_iframe                              58871 non-null  float64\n",
      " 3   int                                     58871 non-null  float64\n",
      " 4   org                                     58871 non-null  float64\n",
      " 5   gov                                     58871 non-null  float64\n",
      " 6   in                                      58871 non-null  float64\n",
      " 7   eu                                      58871 non-null  float64\n",
      " 8   cn                                      58871 non-null  float64\n",
      " 9   kr                                      58871 non-null  float64\n",
      " 10  url_depth                               58871 non-null  float64\n",
      " 11  subdomain_level                         58871 non-null  float64\n",
      " 12  param_cnt                               58871 non-null  float64\n",
      " 13  title_length                            58871 non-null  float64\n",
      " 14  internal_js_cnt                         58871 non-null  float64\n",
      " 15  external_js_cnt                         58871 non-null  float64\n",
      " 16  charset                                 58871 non-null  float64\n",
      " 17  hyperlink_cnt                           58871 non-null  float64\n",
      " 18  first_appear                            58871 non-null  float64\n",
      " 19  total_num_of_paper_citing               58871 non-null  float64\n",
      " 20  total_num_of_author_citing              58871 non-null  float64\n",
      " 21  total_num_of_affiliation_citing         58871 non-null  float64\n",
      " 22  total_num_of_journal_citing             58871 non-null  float64\n",
      " 23  total_num_of_author_self_citation       58871 non-null  float64\n",
      " 24  total_num_of_affiliation_self_citation  58871 non-null  float64\n",
      " 25  total_num_of_journal_self_citation      58871 non-null  float64\n",
      " 26  avg_year                                58871 non-null  float64\n",
      " 27  min_year                                58871 non-null  float64\n",
      " 28  max_year                                58871 non-null  float64\n",
      " 29  median                                  58871 non-null  float64\n",
      " 30  num_of_author                           58871 non-null  float64\n",
      " 31  num_of_author_citing                    58871 non-null  float64\n",
      " 32  num_of_affiliation_citing               58871 non-null  float64\n",
      " 33  num_of_journal_citing                   58871 non-null  float64\n",
      " 34  avg_hindex                              58871 non-null  float64\n",
      " 35  first_author_hindex                     58871 non-null  float64\n",
      " 36  last_author_hindex                      58871 non-null  float64\n",
      " 37  avg_mid_author_hindex                   58871 non-null  float64\n",
      " 38  paper_unique_affiliation                58871 non-null  float64\n",
      " 39  scaled_first_appear                     58871 non-null  float64\n",
      " 40  label                                   58871 non-null  float64\n",
      " 41  url                                     58871 non-null  object \n",
      "dtypes: float64(41), object(1)\n",
      "memory usage: 19.3+ MB\n",
      "raw_data: (58871, 42)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "seed = 77\n",
    "\n",
    "data_file = '../data/untrunc_data_cleaned_url.csv'\n",
    "\n",
    "raw_data = pd.read_table(data_file, sep=',', index_col=0)\n",
    "raw_data = raw_data.dropna()\n",
    "\n",
    "raw_data.info()\n",
    "\n",
    "print(f'raw_data: {raw_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T23:24:40.078399Z",
     "start_time": "2021-01-24T23:24:38.549818Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "x = raw_data.drop(['label', 'first_appear', 'url'], axis=1)\n",
    "y = raw_data.label\n",
    "y = preprocessing.StandardScaler().fit_transform(y.values.reshape(-1, 1))\n",
    "y = pd.DataFrame(y).iloc[:,0]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size = 0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T23:24:40.167044Z",
     "start_time": "2021-01-24T23:24:40.083240Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated 16 CPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "cpu_cnt = multiprocessing.cpu_count()\n",
    "allocated_cpu = cpu_cnt\n",
    "print(f\"Allocated {allocated_cpu} CPUs\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T23:24:40.352238Z",
     "start_time": "2021-01-24T23:24:40.172043Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing, clone\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils.validation import _check_fit_params\n",
    "\n",
    "\n",
    "class VerboseGridSearchCV(GridSearchCV):\n",
    "\n",
    "    def __init__(self, estimator, param_grid, *, scoring=None,\n",
    "                 n_jobs=None, iid='deprecated', refit=True, cv=None,\n",
    "                 verbose=0, pre_dispatch='2*n_jobs',\n",
    "                 error_score=np.nan, return_train_score=False):\n",
    "        super().__init__(\n",
    "            estimator=estimator, param_grid=param_grid, scoring=scoring,\n",
    "            n_jobs=n_jobs, iid=iid, refit=refit, cv=cv, verbose=verbose,\n",
    "            pre_dispatch=pre_dispatch, error_score=error_score,\n",
    "            return_train_score=return_train_score)\n",
    "        self.estimators_ = list()\n",
    "        self.params_ = list()\n",
    "\n",
    "    def fit(self, X, y=None, *, groups=None, **fit_params):\n",
    "        super(VerboseGridSearchCV, self).fit(X, y=y, groups=groups, **fit_params)\n",
    "        if not self.refit:\n",
    "            return self\n",
    "        results = self.cv_results_\n",
    "\n",
    "        fit_params = _check_fit_params(X, fit_params)\n",
    "        for idx in range(len(results[\"params\"])):\n",
    "            params = results[\"params\"][idx]\n",
    "            estimator = clone(clone(clone(self.estimator)).set_params(**params))\n",
    "            if y is not None:\n",
    "                estimator.fit(X, y, **fit_params)\n",
    "            else:\n",
    "                estimator.fit(X, **fit_params)\n",
    "\n",
    "            self.estimators_.append(estimator)\n",
    "            self.params_.append(params)\n",
    "\n",
    "        grid.params_ = pd.DataFrame.from_dict(grid.params_)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L-BFGS-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T14:31:09.695005Z",
     "start_time": "2021-01-24T23:24:40.356682Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x7f0e561e3d30 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjian03/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/home/jjian03/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 347, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/home/jjian03/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 780, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/home/jjian03/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/jjian03/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/jjian03/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 529, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"/home/jjian03/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\", line 178, in submit\n",
      "    fn, *args, **kwargs)\n",
      "  File \"/home/jjian03/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
      "\n",
      "The exit codes of the workers are {EXIT(2), EXIT(2)}\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(2), EXIT(2)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e51393e43e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_rf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-7557f16f8cb2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerboseGridSearchCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    538\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hzhuang/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hzhuang/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \"\"\"\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 178\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 raise ShutdownExecutorError(\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(2), EXIT(2)}"
     ]
    }
   ],
   "source": [
    "param_rf = {\n",
    "    'max_depth': [*np.arange(1,35,2)],\n",
    "    'n_estimators': [*np.arange(120,200,50)],\n",
    "\n",
    "    'min_samples_split': [*np.arange(10,50,5)],\n",
    "    'min_samples_leaf': [*np.arange(5,40,3)],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "    \n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T14:47:27.469764Z",
     "start_time": "2021-01-25T14:31:09.717197Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.feature_importances_) \\\n",
    "    .apply(pd.Series)\n",
    "feature_importance.columns = X_train.columns\n",
    "feature_importance = grid.params_.join(feature_importance)\n",
    "\n",
    "feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T14:47:29.339253Z",
     "start_time": "2021-01-25T14:47:27.478601Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "out_of_bag_score = pd.Series(grid.estimators_).apply(lambda estimator: estimator.oob_score_)\n",
    "out_of_bag_score.name = 'out_of_bag_score'\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "sns.boxplot(x=out_of_bag_score)\n",
    "\n",
    "plt.title('Distribution of MSE(Out of Bag Score)', fontSize=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T15:51:18.528023Z",
     "start_time": "2021-01-25T14:47:29.350267Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pseudo_r2(y_true, y_hat):\n",
    "    correlation_matrix = np.corrcoef(\n",
    "        y_true.astype(float), \n",
    "        y_hat.astype(float)\n",
    "    )\n",
    "    correlation_xy = correlation_matrix[0,1]\n",
    "    return correlation_xy**2\n",
    "\n",
    "\n",
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T15:51:18.673440Z",
     "start_time": "2021-01-25T15:51:18.549638Z"
    }
   },
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T15:51:25.213380Z",
     "start_time": "2021-01-25T15:51:18.677210Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 2, figsize=(15,20))\n",
    "sns.lineplot(y=\"r_square\", x=\"max_depth\", hue='data_type', style='data_type', data=performance, ax=ax[0, 0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[0, 1])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1, 0])\n",
    "sns.lineplot(y=\"r_square\", x=\"n_estimators\", hue='data_type', style='data_type', data=performance, ax=ax[1, 1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T10:15:58.227821Z",
     "start_time": "2021-01-25T15:51:25.216560Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'n_estimators': [*np.arange(200,400,50)],\n",
    "\n",
    "    'min_samples_split': [*np.arange(20,90,5)],\n",
    "    'min_samples_leaf': [*np.arange(40,240,3)],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    "\n",
    "    max_depth=20,\n",
    "    \n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T11:06:16.184338Z",
     "start_time": "2021-01-26T10:15:58.239469Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T11:06:20.756511Z",
     "start_time": "2021-01-26T11:06:16.189825Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(3, 1, figsize=(17,20))\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "sns.lineplot(y=\"r_square\", x=\"n_estimators\", hue='data_type', style='data_type', data=performance, ax=ax[2])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:35:40.339044Z",
     "start_time": "2021-01-26T11:06:20.763045Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'n_estimators': [*np.arange(200,2000,100)],\n",
    "    'min_samples_split': [*np.arange(150,400,20)],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    "\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=120,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:45:55.274761Z",
     "start_time": "2021-01-26T14:35:40.343835Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:45:57.008507Z",
     "start_time": "2021-01-26T14:45:55.277154Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(17,10))\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"n_estimators\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:18:35.724438Z",
     "start_time": "2021-01-26T14:45:57.010915Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'n_estimators': [*np.arange(200,3000,50)],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    "\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=120,\n",
    "    min_samples_split=250,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:23:29.968715Z",
     "start_time": "2021-01-26T16:18:35.797265Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:23:30.473800Z",
     "start_time": "2021-01-26T16:23:29.974549Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "sns.lineplot(y=\"r_square\", x=\"n_estimators\", hue='data_type', style='data_type', data=performance)\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.223Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'max_depth': [*np.arange(7,15,1)],\n",
    "    'min_samples_leaf': [*np.arange(100,150,10)],\n",
    "    'min_samples_split': [*np.arange(200,300,10)],\n",
    "    'n_estimators': [*np.arange(1400,1700,50)],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.228Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.232Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 2, figsize=(15,15))\n",
    "sns.lineplot(y=\"r_square\", x=\"max_depth\", hue='data_type', style='data_type', data=performance, ax=ax[0, 0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[0, 1])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1, 0])\n",
    "sns.lineplot(y=\"r_square\", x=\"n_estimators\", hue='data_type', style='data_type', data=performance, ax=ax[1, 1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.237Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [*np.arange(100,4000,200)],\n",
    "    'min_samples_split': [*np.arange(100,4000,200)],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    "\n",
    "    n_estimators=50,\n",
    "    max_depth=8,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.242Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.246Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.250Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [*np.arange(250,1000,50)],\n",
    "    'min_samples_split': [*np.arange(100,8000,200)],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    "\n",
    "    n_estimators=50,\n",
    "    max_depth=8,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.254Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.258Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.263Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [*np.arange(250,2500,50)],\n",
    "    'min_samples_split': [*np.arange(100,5000,100)],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    "\n",
    "    n_estimators=50,\n",
    "    max_depth=8,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.268Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.273Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.279Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [*np.arange(100,1250,10)],\n",
    "    'min_samples_split': [*np.arange(100,1000,5)],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    "\n",
    "    n_estimators=50,\n",
    "    max_depth=8,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.283Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.287Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.291Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.295Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_leaf\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_split\", data=performance_diff, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.299Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [220],\n",
    "    'min_samples_split': [300],\n",
    "    'n_estimators': [1500],\n",
    "    'max_depth': [8],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.303Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat_train = grid.best_estimator_.predict(X_train)\n",
    "print(f'R Square on Training set: {get_pseudo_r2(y_train, y_hat_train)}')\n",
    "y_hat_test = grid.best_estimator_.predict(X_test)\n",
    "print(f'R Square on Testing set:  {get_pseudo_r2(y_test, y_hat_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.307Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "\n",
    "def plot_feature_importance(reg_coef, col_names, title):\n",
    "    reg_coef = pd.Series(reg_coef, index=col_names)\n",
    "    reg_coef = reg_coef.sort_values()\n",
    "    matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "    reg_coef.plot(kind=\"barh\",)\n",
    "    plt.title(title, fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.312Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = [*X_train.columns]\n",
    "\n",
    "# Get the model without any penalty term\n",
    "coef = grid.best_estimator_.feature_importances_\n",
    "plot_feature_importance(\n",
    "    coef, feature_names, \n",
    "    \"Coefficients of the Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.317Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [*np.arange(2,10,1)],\n",
    "    'min_samples_split': [*np.arange(2,20,1)],\n",
    "    'n_estimators': [1500],\n",
    "    'max_depth': [8],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.323Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.328Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_leaf\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_split\", data=performance_diff, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.333Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [220],\n",
    "    'min_samples_split': [300],\n",
    "    'n_estimators': [*np.arange(10,1500,5)],\n",
    "    'max_depth': [8],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.337Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.346Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"n_estimators\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"n_estimators\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.350Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [220],\n",
    "    'min_samples_split': [300],\n",
    "    'n_estimators': [*np.arange(2,300,1)],\n",
    "    'max_depth': [8],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.353Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.358Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"n_estimators\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"n_estimators\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.361Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [220],\n",
    "    'min_samples_split': [300],\n",
    "    'n_estimators': [*np.arange(10,20,1)],\n",
    "    'max_depth': [11],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.366Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.371Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"n_estimators\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"n_estimators\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.375Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [*np.arange(150,250,1)],\n",
    "    'min_samples_split': [300],\n",
    "    'n_estimators': [14],\n",
    "    'max_depth': [11],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.379Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.383Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_leaf\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.386Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [*np.arange(220,250,1)],\n",
    "    'min_samples_split': [300],\n",
    "    'n_estimators': [14],\n",
    "    'max_depth': [11],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.390Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.393Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_leaf\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.396Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [228],\n",
    "    'min_samples_split': [*np.arange(2,1000,1)],\n",
    "    'n_estimators': [14],\n",
    "    'max_depth': [11],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.400Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.403Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_split\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.408Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [230],\n",
    "    'min_samples_split': [*np.arange(475,500,1)],\n",
    "    'n_estimators': [14],\n",
    "    'max_depth': [11],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.411Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.414Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_split\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.417Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [230],\n",
    "    'min_samples_split': [490],\n",
    "    'n_estimators': [*np.arange(20,60,1)],\n",
    "    'max_depth': [11],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.420Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.425Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"n_estimators\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"n_estimators\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.429Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [*np.arange(230,240,1)],\n",
    "    'min_samples_split': [490],\n",
    "    'n_estimators': [30],\n",
    "    'max_depth': [11],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.433Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.436Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_leaf\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_leaf\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.440Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [232],\n",
    "    'min_samples_split': [*np.arange(480,500,1)],\n",
    "    'n_estimators': [30],\n",
    "    'max_depth': [11],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.444Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_train = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_train)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_train, y_hat))\n",
    "r2_test = pd.Series(grid.estimators_) \\\n",
    "    .apply(lambda estimator: estimator.predict(X_test)) \\\n",
    "    .apply(lambda y_hat: get_pseudo_r2(y_test, y_hat))\n",
    "\n",
    "r2_train.name = 'r_square'\n",
    "r2_test.name = 'r_square'\n",
    "\n",
    "performance_train = grid.params_.join(r2_train)\n",
    "performance_test = grid.params_.join(r2_test)\n",
    "performance_train.loc[:, 'data_type'] = 'Training Set'\n",
    "performance_test.loc[:, 'data_type'] = 'Testing Set'\n",
    "\n",
    "performance = performance_train.append(performance_test)\n",
    "\n",
    "r2_diff = r2_train-r2_test\n",
    "r2_diff.name = 'r_square_diff'\n",
    "\n",
    "performance_diff = grid.params_.join(r2_diff)\n",
    "\n",
    "performance_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.448Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "sns.lineplot(y=\"r_square_diff\", x=\"min_samples_split\", data=performance_diff, ax=ax[0])\n",
    "sns.lineplot(y=\"r_square\", x=\"min_samples_split\", hue='data_type', style='data_type', data=performance, ax=ax[1])\n",
    "\n",
    "plt.suptitle(\"Generalization ability inspection\", size=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.452Z"
    }
   },
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'min_samples_leaf': [232],\n",
    "    'min_samples_split': [490],\n",
    "    'n_estimators': [30],\n",
    "    'max_depth': [11],\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    criterion=\"mse\",\n",
    "    verbose=False,\n",
    "    bootstrap=True,\n",
    "    random_state=seed,\n",
    "    warm_start=True,\n",
    "    oob_score = True,\n",
    "    min_weight_fraction_leaf = 0.,\n",
    "    max_features='sqrt',\n",
    "\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.,\n",
    "    max_samples=None,\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "\n",
    "grid = VerboseGridSearchCV(\n",
    "    n_jobs=allocated_cpu,\n",
    "    cv=5,\n",
    "    estimator=rf,\n",
    "    param_grid=param_rf,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.455Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat_train = grid.best_estimator_.predict(X_train)\n",
    "print(f'R Square on Training set: {get_pseudo_r2(y_train, y_hat_train)}')\n",
    "y_hat_test = grid.best_estimator_.predict(X_test)\n",
    "print(f'R Square on Testing set:  {get_pseudo_r2(y_test, y_hat_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.459Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = [*X_train.columns]\n",
    "\n",
    "# Get the model without any penalty term\n",
    "coef = grid.best_estimator_.feature_importances_\n",
    "plot_feature_importance(\n",
    "    coef, feature_names, \n",
    "    \"Coefficients of the Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.462Z"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "explainer = shap.TreeExplainer(grid.best_estimator_)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.466Z"
    }
   },
   "outputs": [],
   "source": [
    "# shap.force_plot(explainer.expected_value, shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.469Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-24T23:24:36.472Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
