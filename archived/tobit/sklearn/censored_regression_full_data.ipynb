{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Code Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "        sys.path.append(path)    \n",
    "add_path('/home/jjian03/anaconda3/lib/python3.7/site-packages')\n",
    "add_path(f'{os.path.abspath(os.path.join(\".\"))}/lib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.Repository import *\n",
    "from lib.Utility import *\n",
    "from lib.modeling import *\n",
    "from lib.preprocessing import *\n",
    "from lib.preprocessing.HTMLParser import html_parser\n",
    "from lib.viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "start_time = time.time()\n",
    "raw_data = DataSource(truncated).raw_data\n",
    "\n",
    "raw_data.info()\n",
    "\n",
    "print(f'raw_data: {shape(raw_data)}')\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_data = DataSource().train_data\n",
    "test_data = DataSource().test_data\n",
    "\n",
    "\n",
    "print('Shape of the dataframe:')\n",
    "print(f'train_data: {shape(train_data)}')\n",
    "print(f'test_data: {len(test_data)}')\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame({\n",
    "    'unique count': print_unique_count(train_data),\n",
    "    'na count': print_na_count(train_data)\n",
    "}, index=train_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st Edition - Combine suffix dummy with MAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine import categorical_encoders\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('label_builder', LabelBuilder()),\n",
    "    ('url_parser', URLParser()),\n",
    "    ('url_length_counter', URLLengthCounter()),\n",
    "    ('url_depth_counter', URLDepthCounter()),\n",
    "    ('has_www_converter', HasWWWConverter()),\n",
    "    ('subdomain_level_counter', SubdomainLevelCounter()),\n",
    "    ('request_parameter_counter', RequestParameterCounter()),\n",
    "    ('domain_suffix_builder', DomainSuffixBuilder()),\n",
    "    ('incorrect_domain_url_cleaner', IncorrectDomainUrlCleaner()),\n",
    "    ('column_renamer', ColumnRenamer({'scheme': 'protocol_type'})),\n",
    "    ('binary_na_encoder', BinaryNAEncoder(['content_type'])),\n",
    "    ('html_parser', html_parser),\n",
    "    ('binary_feature_converter', FeatureValueMapper('protocol_type', {\n",
    "                                        'http': 1,\n",
    "                                        'https':0,\n",
    "                                        })),\n",
    "\n",
    "    ('nan_to_Zero_converter', NanToZeroConverter([\n",
    "        'total_num_of_paper_citing',\n",
    "        'total_num_of_author_citing',\n",
    "        'total_num_of_affiliation_citing',\n",
    "        'total_num_of_journal_citing',\n",
    "        'total_num_of_author_self_citation',\n",
    "        'total_num_of_affiliation_self_citation',\n",
    "        'total_num_of_journal_self_citation',\n",
    "        'avg_year',\n",
    "        'min_year',\n",
    "        'max_year',\n",
    "        'median',\n",
    "        'num_of_author',\n",
    "        'num_of_author_citing',\n",
    "        'num_of_affiliation_citing',\n",
    "        'num_of_journal_citing',\n",
    "        'avg_hindex',\n",
    "        'first_author_hindex',\n",
    "        'last_author_hindex',\n",
    "        'avg_mid_author_hindex',\n",
    "        'paper_unique_affiliation'\n",
    "    ])),\n",
    "    \n",
    "    ('feature_picker', FeaturePicker([\n",
    "                                        'protocol_type',\n",
    "                                        'url_depth',\n",
    "                                        'has_www',\n",
    "                                        'subdomain_level',\n",
    "                                        'param_cnt',\n",
    "                                        'suffix_idx',\n",
    "                                        'is_port_access',\n",
    "                                        'code_size',\n",
    "                                        'title_length',\n",
    "                                        'internal_js_cnt',\n",
    "                                        'external_js_cnt',\n",
    "                                        'charset',\n",
    "                                        'is_html5',\n",
    "                                        'has_iframe',\n",
    "                                        'hyperlink_cnt',\n",
    "\n",
    "                                        'total_num_of_paper_citing',\n",
    "                                        'total_num_of_author_citing',\n",
    "                                        'total_num_of_affiliation_citing',\n",
    "                                        'total_num_of_journal_citing',\n",
    "                                        'total_num_of_author_self_citation',\n",
    "                                        'total_num_of_affiliation_self_citation',\n",
    "                                        'total_num_of_journal_self_citation',\n",
    "                                        'avg_year',\n",
    "                                        'min_year',\n",
    "                                        'max_year',\n",
    "                                        'median',\n",
    "                                        'num_of_author',\n",
    "                                        'num_of_author_citing',\n",
    "                                        'num_of_affiliation_citing',\n",
    "                                        'num_of_journal_citing',\n",
    "                                        'avg_hindex',\n",
    "                                        'first_author_hindex',\n",
    "                                        'last_author_hindex',\n",
    "                                        'avg_mid_author_hindex',\n",
    "                                        'paper_unique_affiliation',\n",
    "\n",
    "                                        'label',\n",
    "                                       ])),\n",
    "    ('dummy_suffix_descritizer', DummySuffixDescritizer()),\n",
    "\n",
    "    ('feature_remover', FeatureRemover([\n",
    "                                        'is_port_access',\n",
    "                                       ])),\n",
    "    ('frequency_indexer', categorical_encoders.CountFrequencyCategoricalEncoder(\n",
    "        encoding_method='frequency',\n",
    "        variables=['charset'])),\n",
    "    ('standard_scaler', CustomizedStandardizer(norm='l2')),\n",
    "\n",
    "])\n",
    "\n",
    "X_train = pipe.fit_transform(DataSource().train_data)\n",
    "y_train = X_train.label\n",
    "X_train = X_train.drop('label', axis=1)\n",
    "print(X_train.columns)\n",
    "\n",
    "X_test = pipe.fit_transform(DataSource().test_data)\n",
    "y_test = X_test.label\n",
    "X_test = X_test.drop('label', axis=1)\n",
    "print(X_test.columns)\n",
    "\n",
    "\n",
    "train = X_train.copy()\n",
    "train.loc[:,'label'] = y_train\n",
    "test = X_test.copy()\n",
    "test.loc[:,'label'] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "param_en = {\n",
    "    'l1_ratio': [0, *np.logspace(-3, 0, 5)],\n",
    "    'alpha': sorted(np.logspace(-2, 1, 20)),\n",
    "    'max_iter': np.arange(10,80,40),\n",
    "}\n",
    "\n",
    "\n",
    "en = ElasticNet(random_state=seed,\n",
    "                       warm_start=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Start to train model\n",
    "result_train, result_test = AnalysisEngineBuilder() \\\n",
    "    .set_X_train(X_train) \\\n",
    "    .set_y_train(y_train) \\\n",
    "    .set_X_test(X_test) \\\n",
    "    .set_y_test(y_test) \\\n",
    "    .set_param_grid(param_en) \\\n",
    "    .set_engine(en) \\\n",
    "    .set_train_strategy(GridSearchStrategy) \\\n",
    "    .build()\n",
    "\n",
    "result_train.best_result.show_performance()\n",
    "print()\n",
    "result_test.best_result.show_performance()\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Visualizer.plot_distribution(pd.DataFrame({\n",
    "    'residual': result_train.best_result.residual\n",
    "}), \"Residual Distribution\", height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_df_train = pd.DataFrame({\n",
    "    'title': 'Training Set',\n",
    "    'residual': result_train.best_result.residual,\n",
    "    'prediction': result_train.best_result.pred,\n",
    "})\n",
    "residual_df_test = pd.DataFrame({\n",
    "    'title': 'Testing Set',\n",
    "    'residual': result_test.best_result.residual,\n",
    "    'prediction': result_test.best_result.pred,\n",
    "})\n",
    "\n",
    "residual_df = residual_df_train.copy().append(residual_df_test)\n",
    "\n",
    "Visualizer.plot_residual(residual_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "param_en = {\n",
    "    'l1_ratio': [0, *np.logspace(-3, 0, 5)],\n",
    "    'alpha': sorted(np.logspace(-2, 1, 20)),\n",
    "    'max_iter': np.arange(10,80,40),\n",
    "}\n",
    "\n",
    "\n",
    "en = ElasticNet(random_state=seed,\n",
    "                       warm_start=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Start to train model\n",
    "result_train, result_test = AnalysisEngineBuilder() \\\n",
    "    .set_X_train(X_train) \\\n",
    "    .set_y_train(y_train) \\\n",
    "    .set_X_test(X_test) \\\n",
    "    .set_y_test(y_test) \\\n",
    "    .set_param_grid(param_en) \\\n",
    "    .set_engine(en) \\\n",
    "    .set_train_strategy(VerboseGridSearchStrategy) \\\n",
    "    .build()\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_visualization_matrix(result_train, result_test):\n",
    "    performance_matrix_train = pd.DataFrame()\n",
    "    performance_matrix_train['alpha'] = pd.Series(result_train.performance_matrix).apply(lambda x: x.params['alpha'][0])\n",
    "    performance_matrix_train['mse'] = pd.Series(result_train.performance_matrix).apply(lambda x: x.mse)\n",
    "    performance_matrix_train['r_2'] = pd.Series(result_train.performance_matrix).apply(lambda x: x.r_2)\n",
    "    for col_name in result_train.performance_matrix[0].rpt.index.tolist():\n",
    "        performance_matrix_train[col_name] = pd.Series(result_train.performance_matrix).apply(lambda x: x.rpt.loc[col_name, 'Coefficients'])\n",
    "    performance_matrix_train['type'] = 'Train'\n",
    "\n",
    "    performance_matrix_test = pd.DataFrame()\n",
    "    performance_matrix_test['alpha'] = pd.Series(result_test.performance_matrix).apply(lambda x: x.params['alpha'][0])\n",
    "    performance_matrix_test['mse'] = pd.Series(result_test.performance_matrix).apply(lambda x: x.mse)\n",
    "    performance_matrix_test['r_2'] = pd.Series(result_test.performance_matrix).apply(lambda x: x.r_2)\n",
    "    for col_name in result_train.performance_matrix[0].rpt.index.tolist():\n",
    "        performance_matrix_test[col_name] = pd.Series(result_test.performance_matrix).apply(lambda x: x.rpt.loc[col_name, 'Coefficients'])\n",
    "    performance_matrix_test['type'] = 'Test'\n",
    "\n",
    "    performance_matrix = pd.DataFrame()\n",
    "    performance_matrix = performance_matrix.append(performance_matrix_train)\n",
    "    performance_matrix = performance_matrix.append(performance_matrix_test)\n",
    "\n",
    "    return performance_matrix\n",
    "\n",
    "performance_matrix = build_visualization_matrix(result_train, result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Visualizer.plot_loss_trend(performance_matrix, 'alpha', 'mse', 'type', 'MSE Trending on Train/Test Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizer.plot_loss_trend(performance_matrix, 'alpha', 'r_2', 'type', 'Adjust R^2 Trending on Train/Test Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizer.plot_importance_trending(X_train, performance_matrix, 'Weight change on each feature', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Visualizer.plot_feature_importance(\n",
    "    result_train.best_result.model.coef_, X_train.columns, \n",
    "    \"Coefficients in the Elastic Net Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Edition - Lasso Regression to Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "param_lso = {\n",
    "    'alpha': sorted(np.logspace(-2, -1, 20)),\n",
    "    'max_iter': np.arange(10,80,40),\n",
    "}\n",
    "\n",
    "\n",
    "lso = Lasso(random_state=seed)\n",
    "\n",
    "\n",
    "# Start to train model\n",
    "result_train, result_test = AnalysisEngineBuilder() \\\n",
    "    .set_X_train(X_train) \\\n",
    "    .set_y_train(y_train) \\\n",
    "    .set_X_test(X_test) \\\n",
    "    .set_y_test(y_test) \\\n",
    "    .set_param_grid(param_lso) \\\n",
    "    .set_engine(lso) \\\n",
    "    .set_train_strategy(VerboseGridSearchStrategy) \\\n",
    "    .build()\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix = build_visualization_matrix(result_train, result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Visualizer.plot_loss_trend(performance_matrix, 'alpha', 'mse', 'type', 'MSE Trending on Train/Test Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizer.plot_loss_trend(performance_matrix, 'alpha', 'r_2', 'type', 'Adjust R^2 Trending on Train/Test Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizer.plot_importance_trending(X_train, performance_matrix, 'Weight change on each feature', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "param_lso = {\n",
    "    'alpha': [0.059],\n",
    "    'max_iter': np.arange(10,80,40),\n",
    "}\n",
    "\n",
    "\n",
    "lso = Lasso(random_state=seed)\n",
    "\n",
    "\n",
    "# Start to train model\n",
    "result_train, result_test = AnalysisEngineBuilder() \\\n",
    "    .set_X_train(X_train) \\\n",
    "    .set_y_train(y_train) \\\n",
    "    .set_X_test(X_test) \\\n",
    "    .set_y_test(y_test) \\\n",
    "    .set_param_grid(param_lso) \\\n",
    "    .set_engine(lso) \\\n",
    "    .set_train_strategy(GridSearchStrategy) \\\n",
    "    .build()\n",
    "\n",
    "result_train.best_result.show_performance()\n",
    "print()\n",
    "result_test.best_result.show_performance()\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt = result_test.best_result.rpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt[rpt.Coefficients == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt.sort_values(by=['Probabilities', 'Standard Errors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Visualizer.plot_feature_importance(\n",
    "    result_train.best_result.model.coef_, X_train.columns, \n",
    "    \"Coefficients in the Elastic Net Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd Edition - Use Selected Features to run Lasso Regression Again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manually select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set(tuple([\n",
    "    'org',\n",
    "    'gov',\n",
    "    'int',\n",
    "    'in',\n",
    "    'cn',\n",
    "    'eu',\n",
    "]))\n",
    "\n",
    "for col_name in rpt[rpt.Coefficients != 0].index.tolist():\n",
    "    features.add(col_name)\n",
    "\n",
    "features.remove('Constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "param_lso = {\n",
    "    'alpha': sorted(np.logspace(-2, -1, 20)),\n",
    "    'max_iter': np.arange(10,80,40),\n",
    "}\n",
    "\n",
    "\n",
    "lso = Lasso(random_state=seed)\n",
    "\n",
    "\n",
    "# Start to train model\n",
    "result_train, result_test = AnalysisEngineBuilder() \\\n",
    "    .set_X_train(X_train[features]) \\\n",
    "    .set_y_train(y_train) \\\n",
    "    .set_X_test(X_test[features]) \\\n",
    "    .set_y_test(y_test) \\\n",
    "    .set_param_grid(param_lso) \\\n",
    "    .set_engine(lso) \\\n",
    "    .set_train_strategy(VerboseGridSearchStrategy) \\\n",
    "    .build()\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix = build_visualization_matrix(result_train, result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Visualizer.plot_importance_trending(X_train[features], performance_matrix, 'Weight change on each feature', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "param_lso = {\n",
    "    'alpha': [0.059],\n",
    "    'max_iter': np.arange(10,80,40),\n",
    "}\n",
    "\n",
    "\n",
    "lso = Lasso(random_state=seed)\n",
    "\n",
    "\n",
    "# Start to train model\n",
    "result_train, result_test = AnalysisEngineBuilder() \\\n",
    "    .set_X_train(X_train[features]) \\\n",
    "    .set_y_train(y_train) \\\n",
    "    .set_X_test(X_test[features]) \\\n",
    "    .set_y_test(y_test) \\\n",
    "    .set_param_grid(param_lso) \\\n",
    "    .set_engine(lso) \\\n",
    "    .set_train_strategy(GridSearchStrategy) \\\n",
    "    .build()\n",
    "\n",
    "result_train.best_result.show_performance()\n",
    "print()\n",
    "result_test.best_result.show_performance()\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt = result_test.best_result.rpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt[rpt.Coefficients == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt.sort_values(by=['Probabilities', 'Standard Errors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Visualizer.plot_feature_importance(\n",
    "    result_train.best_result.model.coef_, X_train[features].columns, \n",
    "    \"Coefficients in the Elastic Net Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4th Edition - Retrain the Elastic Net Regressor with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = rpt[rpt.Coefficients != 0].index.tolist()[1:]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "param_en = {\n",
    "    'l1_ratio': [0, *np.logspace(-3, 0, 5)],\n",
    "    'alpha': sorted(np.logspace(-2, 1, 20)),\n",
    "    'max_iter': np.arange(10,80,40),\n",
    "}\n",
    "\n",
    "\n",
    "en = ElasticNet(random_state=seed,\n",
    "                       warm_start=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Start to train model\n",
    "result_train, result_test = AnalysisEngineBuilder() \\\n",
    "    .set_X_train(X_train[features]) \\\n",
    "    .set_y_train(y_train) \\\n",
    "    .set_X_test(X_test[features]) \\\n",
    "    .set_y_test(y_test) \\\n",
    "    .set_param_grid(param_en) \\\n",
    "    .set_engine(en) \\\n",
    "    .set_train_strategy(VerboseGridSearchStrategy) \\\n",
    "    .build()\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix = build_visualization_matrix(result_train, result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Visualizer.plot_loss_trend(performance_matrix, 'alpha', 'mse', 'type', 'MSE Trending on Train/Test Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizer.plot_loss_trend(performance_matrix, 'alpha', 'r_2', 'type', 'Adjust R^2 Trending on Train/Test Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizer.plot_importance_trending(X_train[features], performance_matrix, 'Weight change on each feature', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "param_en = {\n",
    "    'l1_ratio': [0, *np.logspace(-3, 0, 5)],\n",
    "    'alpha': sorted(np.logspace(-2, 1, 20)),\n",
    "    'max_iter': np.arange(10,80,40),\n",
    "}\n",
    "\n",
    "\n",
    "en = ElasticNet(random_state=seed,\n",
    "                       warm_start=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Start to train model\n",
    "result_train, result_test = AnalysisEngineBuilder() \\\n",
    "    .set_X_train(X_train[features]) \\\n",
    "    .set_y_train(y_train) \\\n",
    "    .set_X_test(X_test[features]) \\\n",
    "    .set_y_test(y_test) \\\n",
    "    .set_param_grid(param_en) \\\n",
    "    .set_engine(en) \\\n",
    "    .set_train_strategy(GridSearchStrategy) \\\n",
    "    .build()\n",
    "\n",
    "result_train.best_result.show_performance()\n",
    "print()\n",
    "result_test.best_result.show_performance()\n",
    "\n",
    "t = str(datetime.timedelta(seconds=time.time() - start_time)).split(':')\n",
    "print(\"--- %s minutes, %.2f seconds ---\" % (t[1], float(t[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Visualizer.plot_feature_importance(\n",
    "    result_train.best_result.model.coef_, X_train[features].columns, \n",
    "    \"Coefficients in the Elastic Net Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
